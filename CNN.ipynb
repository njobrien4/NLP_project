{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gzip\n",
    "import numpy as np\n",
    "\n",
    "def convert_to_list(filename):\n",
    "    if filename.endswith('gz'):\n",
    "        with gzip.open(filename,'r')as f:\n",
    "            text_tokens = f.readlines()\n",
    "    else:\n",
    "        with open(filename, 'r') as f:\n",
    "            text_tokens = f.readlines()\n",
    "    text_tokens = [token.replace('\\n','').split('\\t') for token in text_tokens]\n",
    "    return text_tokens\n",
    "\n",
    "def convert_to_samples(filename):\n",
    "    my_list=convert_to_list(filename)\n",
    "    new_samples=[]\n",
    "    for original_sample in my_list:\n",
    "        for similar in original_sample[1]:\n",
    "            new_samples.append([original_sample[0], similar, original_sample[2][0]])# change this to include all negative \n",
    "                                                                                   # examples later\n",
    "    return new_samples\n",
    "def make_lookup_table_for_training_data(filename):\n",
    "    lookup={}\n",
    "    text_token_list=convert_to_list(filename)\n",
    "    for token in text_token_list:\n",
    "        lookup[token[0]]={'title':token[1],'question':token[2]}\n",
    "    return lookup\n",
    "        \n",
    "    \n",
    "\n",
    "#takes  sample_ids of [[q1,p1,n1],[q2,p2,n2]....]\n",
    "#outputs titles like [[q1_title, p1_title, n1_title],[q2_title,p2_title,n2_title]...]\n",
    "def convert_sampleids_to_titles(sample_ids,lookup):\n",
    "    #each sample_id [question_id, pos_id, neg_id]\n",
    "    titles = []\n",
    "    for sample_id in sample_ids:\n",
    "        titles.append([lookup[str(identity)]['title'] for identity in sample_id])\n",
    "    return titles\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-025d1d692f1c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mlookup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_lookup_table_for_training_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_tokenized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_sampleids_to_titles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlookup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-d55a01478d56>\u001b[0m in \u001b[0;36mconvert_sampleids_to_titles\u001b[0;34m(sample_ids, lookup)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mtitles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msample_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msample_ids\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mtitles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlookup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midentity\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msample_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtitles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '2'"
     ]
    }
   ],
   "source": [
    "#text_tokenized.txt.gz has id \\t title \\t question body\n",
    "text_tokenized='askubuntu/text_tokenized.txt.gz'\n",
    "\n",
    "#train_random.txt\n",
    "#(1) the query question ID, (2) the list of similar question IDs, and (3) the list of randomly selected question IDs.\n",
    "train_random_filename='askubuntu/train_random.txt'\n",
    "\n",
    "#Each line contains (1) the query question ID, (2) the list of similar question IDs, (3) the list of 20 candidate question IDs and (4) the associated BM25 scores of these questions computed by the Lucene search engine. The second field (the set of similar questions) is a subset of the third field.\n",
    "dev_filename='askubuntu/dev.txt'\n",
    "test_filename='askubuntu/test.txt'\n",
    "\n",
    "train = convert_to_samples(train_random_filename)\n",
    "dev = convert_to_samples(dev_filename)\n",
    "test = convert_to_samples(test_filename)\n",
    "\n",
    "lookup = make_lookup_table_for_training_data(text_tokenized)\n",
    "\n",
    "train = convert_sampleids_to_titles(train, lookup)\n",
    "print train\n",
    "train[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embeddings = 'askubuntu/vector/vectors_pruned.200.txt.gz'\n",
    "f = gzip.open(word_embeddings, 'r')\n",
    "wv_text = [ ]\n",
    "lines = f.readlines()\n",
    "for line in lines:\n",
    "    wv_text.append(line.strip())\n",
    "\n",
    "word_to_vec = {}\n",
    "\n",
    "for line in wv_text:\n",
    "    parts = line.split()\n",
    "    word = parts[0]\n",
    "    vector = np.array([float(v) for v in parts[1:]])\n",
    "    word_to_vec[word] = vector\n",
    "f.close()\n",
    "\n",
    "def extract_features(word):\n",
    "    word=word.encode('utf-8')\n",
    "    return word_to_vec.get(word,[0.0 for i in range(200)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  6.81100000e-03,  -1.91690000e-02,   3.72350000e-02,\n",
       "         1.88340000e-02,   7.88700000e-03,  -6.64640000e-02,\n",
       "         8.59540000e-02,  -8.24730000e-02,   1.83440000e-02,\n",
       "        -8.74610000e-02,  -1.11447000e-01,  -3.71180000e-02,\n",
       "        -8.30300000e-03,   1.40190000e-02,   8.45250000e-02,\n",
       "         2.03400000e-03,  -2.82450000e-02,  -1.62900000e-02,\n",
       "         7.20170000e-02,   6.04480000e-02,  -1.39264000e-01,\n",
       "        -1.63540000e-02,   1.74352000e-01,   3.68500000e-03,\n",
       "        -9.88580000e-02,  -4.12110000e-02,  -4.93310000e-02,\n",
       "        -2.85100000e-02,  -9.08550000e-02,  -2.40180000e-02,\n",
       "        -9.21600000e-03,  -3.20450000e-02,  -3.30730000e-02,\n",
       "        -2.61440000e-02,   1.22893000e-01,  -3.29470000e-02,\n",
       "        -9.37550000e-02,   1.87461000e-01,   1.35400000e-03,\n",
       "         7.04130000e-02,   3.89100000e-03,  -2.50700000e-02,\n",
       "        -1.38250000e-02,   5.29970000e-02,  -9.65200000e-02,\n",
       "         5.73710000e-02,  -1.60480000e-02,   3.27330000e-02,\n",
       "         5.89300000e-02,   4.26530000e-02,  -1.06370000e-02,\n",
       "         4.93350000e-02,   8.89100000e-02,  -2.64200000e-03,\n",
       "         2.14790000e-02,  -1.32110000e-01,   8.38400000e-02,\n",
       "        -1.45993000e-01,  -5.50810000e-02,  -4.46940000e-02,\n",
       "         2.99750000e-02,   7.34200000e-03,  -1.41483000e-01,\n",
       "        -1.34992000e-01,   7.93700000e-03,   1.45378000e-01,\n",
       "        -3.50880000e-02,   6.77400000e-02,  -1.71040000e-02,\n",
       "         1.76290000e-02,   4.40340000e-02,  -7.18210000e-02,\n",
       "         1.02433000e-01,   3.35520000e-02,   2.11950000e-02,\n",
       "         2.98280000e-02,  -1.54515000e-01,  -2.36050000e-02,\n",
       "         3.20910000e-02,  -1.22121000e-01,  -4.24300000e-02,\n",
       "         1.00603000e-01,  -6.18580000e-02,   3.81820000e-02,\n",
       "        -4.36510000e-02,  -3.56280000e-02,  -6.03380000e-02,\n",
       "         1.80000000e-04,   2.48590000e-02,   7.88110000e-02,\n",
       "        -4.44400000e-02,  -2.40390000e-02,  -4.79100000e-02,\n",
       "         1.14525000e-01,   5.66190000e-02,  -5.52450000e-02,\n",
       "        -4.29180000e-02,  -1.61904000e-01,   1.26530000e-02,\n",
       "        -6.81030000e-02,  -3.02740000e-02,   5.56300000e-03,\n",
       "        -2.04090000e-01,   3.45900000e-03,  -4.42810000e-02,\n",
       "        -3.35830000e-02,   1.15700000e-03,  -3.03010000e-02,\n",
       "        -1.24050000e-02,  -9.53550000e-02,  -3.93550000e-02,\n",
       "         6.22650000e-02,  -4.42020000e-02,   8.81300000e-03,\n",
       "        -4.53580000e-02,  -5.34300000e-03,  -1.47241000e-01,\n",
       "         1.08890000e-02,   1.23100000e-02,   1.21187000e-01,\n",
       "         1.01320000e-02,  -3.62640000e-02,  -6.49760000e-02,\n",
       "         5.65480000e-02,   4.79890000e-02,   1.92400000e-03,\n",
       "         3.64970000e-02,  -2.26600000e-03,   1.00555000e-01,\n",
       "         3.12180000e-02,  -4.39490000e-02,  -1.24266000e-01,\n",
       "        -1.14630000e-02,  -1.15645000e-01,  -9.02710000e-02,\n",
       "        -8.23100000e-03,   3.45000000e-04,  -4.42670000e-02,\n",
       "        -5.25660000e-02,  -3.55760000e-02,  -7.44500000e-03,\n",
       "        -8.52170000e-02,  -1.80300000e-02,  -6.08760000e-02,\n",
       "         1.16299000e-01,   7.59800000e-03,  -2.05000000e-02,\n",
       "        -7.56390000e-02,  -9.87520000e-02,  -1.76250000e-02,\n",
       "        -1.02854000e-01,  -1.51860000e-01,  -9.26320000e-02,\n",
       "         6.58400000e-03,  -2.72720000e-02,  -5.68420000e-02,\n",
       "        -5.13840000e-02,  -4.56000000e-03,  -1.53380000e-02,\n",
       "         4.77810000e-02,   1.58880000e-02,   9.67640000e-02,\n",
       "         3.90780000e-02,   5.76590000e-02,  -1.34597000e-01,\n",
       "         5.30760000e-02,   1.08641000e-01,  -1.65740000e-02,\n",
       "        -3.55110000e-02,   1.21346000e-01,  -5.96160000e-02,\n",
       "        -2.46370000e-02,   9.78130000e-02,  -9.35810000e-02,\n",
       "        -1.11922000e-01,  -1.29078000e-01,   1.11417000e-01,\n",
       "        -1.19060000e-02,  -9.07660000e-02,  -6.25830000e-02,\n",
       "        -7.62640000e-02,   1.75780000e-02,  -1.09919000e-01,\n",
       "        -3.83820000e-02,   4.49640000e-02,  -1.06710000e-02,\n",
       "         3.48420000e-02,   8.67690000e-02,  -1.06745000e-01,\n",
       "         2.37510000e-02,   1.18238000e-01,   4.80480000e-02,\n",
       "         5.87720000e-02,  -8.39270000e-02,  -9.64800000e-03,\n",
       "        -3.85590000e-02,  -1.38668000e-01,   2.74070000e-02,\n",
       "        -6.86650000e-02,   3.87500000e-03])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_features('laptop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sample_ids' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-17979c8454fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0msample_ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'sample_ids' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "print sample_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
